{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f65da002-1f09-47b0-a832-b38687f3bac0",
   "metadata": {},
   "source": [
    "# Task 2: Apply Distribution/feature matching method to selected architecture in part 2 on the MNIST dataset\n",
    "In the code provided, the distribution matching is implemented within the training loop, specifically in the section where the synthetic data is trained against the real data.\n",
    "\n",
    "The paper refered to this code is: *\"B. Zhao and H. Bilen, “Dataset condensation with distribution matching,” in 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2023, pp. 6503–6512.\"*\n",
    "\n",
    "Reference code: https://github.com/VICO-UoE/DatasetCondensation/blob/master/main_DM.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0159e34-471c-4f27-b47c-221399438eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\manis\\\\Documents\\\\ECE course\\\\Project A')\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from utils_Task2_DM import get_loops, get_dataset, get_network, get_eval_pool, evaluate_synset, get_daparam, match_loss, get_time, TensorDataset, epoch, DiffAugment, ParamDiffAug\n",
    "from networks import ConvNet\n",
    "\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc9ac7a-d10b-4b3a-9233-f86718c5dd91",
   "metadata": {},
   "source": [
    "      ################# The code from here just use ConvnetD3 for MNIST as in the Project A Task 2(a) ###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01f2a08-bb07-4691-88fb-3df1a3ff6c73",
   "metadata": {},
   "source": [
    "# With ConvNetD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3848c-c582-4353-8424-37cbb33cf93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if 'ipykernel' in sys.modules:\n",
    "        print(\"Running in a Jupyter environment. Overriding sys.argv.\")\n",
    "        sys.argv = [''] \n",
    "        \n",
    "        # Parse command-line arguments\n",
    "        parser = argparse.ArgumentParser(description='Parameter Processing')\n",
    "        parser.add_argument('--dataset', type=str, default='MNIST', help='dataset')\n",
    "        parser.add_argument('--ipc', type=int, default=10, help='image(s) per class')  # for MNIST it's 10. For MHIST, it's 50\n",
    "        parser.add_argument('--eval_mode', type=str, default='SS', help='eval_mode')  # S: same as training model\n",
    "        parser.add_argument('--num_exp', type=int, default=5, help='number of experiments')\n",
    "        parser.add_argument('--num_eval', type=int, default=20, help='number of evaluating models')\n",
    "        parser.add_argument('--epoch_eval_train', type=int, default=20, help='epochs for model training with synthetic data')#1000\n",
    "        parser.add_argument('--Iteration', type=int, default=10, help='training iterations') #20000, update to 10 steps: suggested in Assignment\n",
    "        parser.add_argument('--lr_img', type=float, default=0.01, help='learning rate for synthetic images') # 1.0\n",
    "        parser.add_argument('--lr_net', type=float, default=0.01, help='learning rate for network parameters')\n",
    "        parser.add_argument('--batch_real', type=int, default=256, help='batch size for real data')\n",
    "        parser.add_argument('--batch_train', type=int, default=256, help='batch size for training networks')\n",
    "        parser.add_argument('--init', type=str, default='real', help='initialize synthetic images from noise or real')\n",
    "        parser.add_argument('--dsa_strategy', type=str, default='color_crop_cutout_flip_scale_rotate', help='differentiable Siamese augmentation strategy')\n",
    "        parser.add_argument('--data_path', type=str, default='data', help='dataset path')\n",
    "        parser.add_argument('--save_path', type=str, default='result', help='path to save results')\n",
    "        parser.add_argument('--dis_metric', type=str, default='ours', help='distance metric')\n",
    "\n",
    "        args = parser.parse_args()\n",
    "        args.method = 'DM'\n",
    "        args.outer_loop, args.inner_loop = get_loops(args.ipc)\n",
    "        args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        args.dsa_param = ParamDiffAug()\n",
    "        args.dsa = False if args.dsa_strategy in ['none', 'None'] else True\n",
    "\n",
    "        # Creating necessary directories if not present\n",
    "        if not os.path.exists(args.data_path):\n",
    "            os.mkdir(args.data_path)\n",
    "\n",
    "        if not os.path.exists(args.save_path):\n",
    "            os.mkdir(args.save_path)\n",
    "\n",
    "        # Set evaluation iterations\n",
    "        eval_it_pool = np.arange(0, args.Iteration + 1, 500).tolist() if args.eval_mode in ['S', 'SS'] else [args.Iteration]\n",
    "        print('eval_it_pool: ', eval_it_pool)\n",
    "\n",
    "        ''' Load the MNIST dataset '''\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        channel = 1\n",
    "        im_size = (28, 28) # im_size = (32, 32) \n",
    "        num_classes = 10\n",
    "        mean = (0.1307,)\n",
    "        std = (0.3081,)\n",
    "\n",
    "        dst_train = MNIST(args.data_path, train=True, download=True, transform=transform)\n",
    "        dst_test = MNIST(args.data_path, train=False, download=True, transform=transform)\n",
    "        testloader = DataLoader(dst_test, batch_size=args.batch_real, shuffle=False)\n",
    "\n",
    "        ''' Convnet3 for MNIST dataset '''\n",
    "    # Set parameters for ConvNetD3\n",
    "    channel_mnist = 1  # Grayscale images (MNIST)\n",
    "    num_classes_mnist = 10  # MNIST has 10 classes\n",
    "    im_size_mnist = (32, 32)  # Actual MNIST image size is 28x28\n",
    "    \n",
    "    # Resize MNIST images from 28x28 to 32x32\n",
    "    transform_resize = transforms.Compose([\n",
    "    transforms.Resize(im_size_mnist),  # Resize to 32x32\n",
    "    transforms.ToTensor()  # Convert to tensor\n",
    "    ])\n",
    "    \n",
    "    # Instantiate ConvNetD3\n",
    "    convnet3 = get_network('ConvNetD3', channel_mnist, num_classes_mnist, im_size_mnist).to('cpu')\n",
    "    optimizer3 = optim.SGD(convnet3.parameters(), lr=0.01) # Define optimizer\n",
    "    criterion = nn.CrossEntropyLoss() # Define loss function\n",
    "    mnist_loader = DataLoader(dst_train, batch_size=256, shuffle=True) # Create DataLoaders\n",
    "    scheduler3 = CosineAnnealingLR(optimizer3, T_max=20)# Cosine Annealing Scheduler\n",
    "\n",
    "    # Create a pool of models for evaluation\n",
    "    model_eval_pool = get_eval_pool(args.eval_mode, 'ConvNetD3', 'ConvNetD3')\n",
    "    accs_all_exps = dict()  # Record performance of all experiments\n",
    "    for key in model_eval_pool:\n",
    "        accs_all_exps[key] = []\n",
    "\n",
    "    data_save = []\n",
    "\n",
    "    for exp in range(args.num_exp):\n",
    "        print(f'\\n================== Exp {exp} ==================\\n')\n",
    "        print('Hyper-parameters: \\n', args.__dict__)\n",
    "        print('Evaluation model pool: ', model_eval_pool)\n",
    "\n",
    "        ''' Organize the real dataset '''\n",
    "        images_all = [torch.unsqueeze(dst_train[i][0], dim=0) for i in range(len(dst_train))]\n",
    "        labels_all = [dst_train[i][1] for i in range(len(dst_train))]\n",
    "        images_all = torch.cat(images_all, dim=0).to(args.device)\n",
    "        labels_all = torch.tensor(labels_all, dtype=torch.long, device=args.device)\n",
    "\n",
    "        # Class-wise image indices\n",
    "        indices_class = [[] for _ in range(num_classes)]\n",
    "        for i, lab in enumerate(labels_all):\n",
    "            indices_class[lab].append(i)\n",
    "        \n",
    "        # Display class distribution\n",
    "        for c in range(num_classes):\n",
    "            print(f'class {c} = {len(indices_class[c])} real images')\n",
    "        \n",
    "        # Helper function to fetch random images from a class\n",
    "        def get_images(c, n):  # Get random n images from class c\n",
    "            idx_shuffle = np.random.permutation(indices_class[c])[:n]\n",
    "            return images_all[idx_shuffle]\n",
    "\n",
    "        ''' Initialize the synthetic data '''\n",
    "        image_syn = torch.randn(size=(num_classes * args.ipc, channel, im_size[0], im_size[1]), dtype=torch.float, requires_grad=True, device=args.device)\n",
    "        label_syn = torch.tensor([np.ones(args.ipc) * i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1)\n",
    "        \n",
    "        # Initialize synthetic images with real or random noise\n",
    "        if args.init == 'real':\n",
    "            print('Initialize synthetic data from random real images')\n",
    "            for c in range(num_classes):\n",
    "                image_syn.data[c * args.ipc:(c + 1) * args.ipc] = get_images(c, args.ipc).detach().data\n",
    "        else:\n",
    "            print('Initialize synthetic data from random noise')\n",
    "\n",
    "        ''' Training '''\n",
    "        optimizer_img = torch.optim.SGD(convnet3.parameters(), lr=0.01)# optimizer_img = torch.optim.SGD([image_syn], lr=args.lr_img, momentum=0.5)\n",
    "        optimizer_img.zero_grad()\n",
    "        print('%s training begins' % time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "\n",
    "        for it in range(args.Iteration + 1):\n",
    "                ''' Evaluate synthetic data '''\n",
    "                if it in eval_it_pool:\n",
    "                    for model_eval in model_eval_pool:\n",
    "                        print(f'-------------------------\\nEvaluation\\nmodel_train = {'ConvNetD3'}, model_eval = {model_eval}, iteration = {it}')\n",
    "                        accs = []\n",
    "                        for it_eval in range(args.num_eval):\n",
    "                            net_eval = get_network(model_eval, channel, num_classes, im_size).to(args.device)\n",
    "                            image_syn_eval, label_syn_eval = copy.deepcopy(image_syn.detach()), copy.deepcopy(label_syn.detach())\n",
    "                            _, acc_train, acc_test = evaluate_synset(it_eval, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "                            accs.append(acc_test)\n",
    "                        print(f'Evaluate {len(accs)} random {model_eval}, mean = {np.mean(accs):.4f} std = {np.std(accs):.4f}\\n-------------------------')\n",
    "\n",
    "                        if it == args.Iteration:\n",
    "                            accs_all_exps[model_eval] += accs\n",
    "\n",
    "                    save_name = os.path.join(args.save_path, f'vis_{args.method}_{args.dataset}_{'ConvNetD3'}_{args.ipc}ipc_exp{exp}_iter{it}.png') \n",
    "                    image_syn_vis = copy.deepcopy(image_syn.detach().cpu())\n",
    "                    for ch in range(channel):\n",
    "                        image_syn_vis[:, ch] = image_syn_vis[:, ch] * std[ch] + mean[ch]\n",
    "                    # image_syn_vis[image_syn_vis < 0] = 0.0\n",
    "                    # image_syn_vis[image_syn_vis > 1] = 1.0\n",
    "                    image_syn_vis = copy.deepcopy(image_syn.detach().cpu())\n",
    "                    image_syn_vis = (image_syn_vis - image_syn_vis.min()) / (image_syn_vis.max() - image_syn_vis.min())\n",
    "                    save_image(image_syn_vis, save_name, nrow=args.ipc)\n",
    "\n",
    "                ''' Train synthetic data '''\n",
    "                net = get_network('ConvNetD3', channel, num_classes, im_size).to(args.device)\n",
    "                net.train()\n",
    "                for param in net.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "                embed = net.module.embed if torch.cuda.device_count() > 1 else net.embed\n",
    "\n",
    "                loss_avg = 0\n",
    "                loss = torch.tensor(0.0).to(args.device)\n",
    "                for c in range(num_classes):\n",
    "                    img_real = get_images(c, args.batch_real)\n",
    "                    img_syn = image_syn[c * args.ipc:(c + 1) * args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "\n",
    "                    if args.dsa:\n",
    "                        seed = int(time.time() * 1000) % 100000\n",
    "                        img_real = DiffAugment(img_real, args.dsa_strategy, seed=seed, param=args.dsa_param)\n",
    "                        img_syn = DiffAugment(img_syn, args.dsa_strategy, seed=seed, param=args.dsa_param)\n",
    "\n",
    "                    output_real = embed(img_real).detach()\n",
    "                    output_syn = embed(img_syn)\n",
    "\n",
    "                    # Calculate the distribution matching loss\n",
    "                    loss += torch.sum((torch.mean(output_real, dim=0) - torch.mean(output_syn, dim=0)) ** 2)\n",
    "\n",
    "                optimizer_img.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer_img.step()\n",
    "                loss_avg += loss.item()\n",
    "\n",
    "                if it % 10 == 0:\n",
    "                    print(f'{time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())} iter = {it:05d}, loss = {loss_avg:.4f}')\n",
    "\n",
    "                if it == args.Iteration:\n",
    "                    data_save.append([copy.deepcopy(image_syn.detach().cpu()), copy.deepcopy(label_syn.detach().cpu())])\n",
    "\n",
    "        print('%s training ends' % time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "\n",
    "    accs = []\n",
    "    for key in model_eval_pool:\n",
    "        accs.append(np.mean(accs_all_exps[key]))\n",
    "    print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'\n",
    "          % (args.num_exp, 'ConvNetD3', np.mean(accs), np.std(accs))) # % (args.num_exp, args.model, np.mean(accs), np.std(accs)))\n",
    "    \n",
    "    current_dir = os.getcwd()# Get the current working directory\n",
    "    # Save the results in the same directory as the script\n",
    "    torch.save({'data': data_save, 'accs_all_exps': accs_all_exps}, \n",
    "                os.path.join(current_dir, f'res_{args.method}_{args.dataset}_convnet3_{args.ipc}ipc.pt'))\n",
    "    \n",
    "    print(f'Data saved to {os.path.join(current_dir, f\"res_{args.method}_{args.dataset}_convnet3_{args.ipc}ipc.pt\")}')\n",
    "\n",
    "    return \n",
    "\n",
    "if __name__ == '__main__':\n",
    "     main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8b4842-3849-4f9e-8666-c019f44e75b0",
   "metadata": {},
   "source": [
    "# With Restnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac616cbd-f526-4d5d-803a-778fc4aa1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Check if running inside a Jupyter Notebook environment\n",
    "    if 'ipykernel' in sys.modules:\n",
    "        print(\"Running in a Jupyter environment. Overriding sys.argv.\")\n",
    "        sys.argv = ['']  # Clear sys.argv to avoid passing unwanted arguments\n",
    "\n",
    "        parser = argparse.ArgumentParser(description='Parameter Processing')\n",
    "        parser.add_argument('--dataset', type=str, default='MNIST', help='dataset')\n",
    "        parser.add_argument('--ipc', type=int, default=10, help='image(s) per class')  # for MNIST it's 10. For MHIST, it's 50\n",
    "        parser.add_argument('--eval_mode', type=str, default='SS', help='eval_mode')  # S: same as training model\n",
    "        parser.add_argument('--num_exp', type=int, default=5, help='number of experiments')\n",
    "        parser.add_argument('--num_eval', type=int, default=20, help='number of evaluating models')\n",
    "        parser.add_argument('--epoch_eval_train', type=int, default=20, help='epochs for model training with synthetic data')#1000\n",
    "        parser.add_argument('--Iteration', type=int, default=10, help='training iterations') #20000, update to 10 steps: suggested in Assignment\n",
    "        parser.add_argument('--lr_img', type=float, default=0.01, help='learning rate for synthetic images') # 1.0\n",
    "        parser.add_argument('--lr_net', type=float, default=0.01, help='learning rate for network parameters')\n",
    "        parser.add_argument('--batch_real', type=int, default=256, help='batch size for real data')\n",
    "        parser.add_argument('--batch_train', type=int, default=256, help='batch size for training networks')\n",
    "        parser.add_argument('--init', type=str, default='real', help='initialize synthetic images from noise or real')\n",
    "        parser.add_argument('--dsa_strategy', type=str, default='color_crop_cutout_flip_scale_rotate', help='differentiable Siamese augmentation strategy')\n",
    "        parser.add_argument('--data_path', type=str, default='data', help='dataset path')\n",
    "        parser.add_argument('--save_path', type=str, default='result', help='path to save results')\n",
    "        parser.add_argument('--dis_metric', type=str, default='ours', help='distance metric')\n",
    "\n",
    "        args = parser.parse_args()\n",
    "        args.method = 'DM'\n",
    "        args.outer_loop, args.inner_loop = get_loops(args.ipc)\n",
    "        args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        args.dsa_param = ParamDiffAug()\n",
    "        args.dsa = False if args.dsa_strategy in ['none', 'None'] else True\n",
    "\n",
    "        # Creating necessary directories if not present\n",
    "        if not os.path.exists(args.data_path):\n",
    "            os.mkdir(args.data_path)\n",
    "\n",
    "        if not os.path.exists(args.save_path):\n",
    "            os.mkdir(args.save_path)\n",
    "\n",
    "        # Set evaluation iterations\n",
    "        eval_it_pool = np.arange(0, args.Iteration + 1, 500).tolist() if args.eval_mode in ['S', 'SS'] else [args.Iteration]\n",
    "        print('eval_it_pool: ', eval_it_pool)\n",
    "\n",
    "        ''' Load the MNIST dataset '''\n",
    "        # transform = transforms.Compose([transforms.ToTensor()])\n",
    "        transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),  # Resize to 32x32\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        channel = 1\n",
    "        # im_size = (28, 28) # im_size = (32, 32) \n",
    "        num_classes = 10\n",
    "        mean = (0.1307,)\n",
    "        std = (0.3081,)\n",
    "\n",
    "        dst_train = MNIST(args.data_path, train=True, download=True, transform=transform)\n",
    "        dst_test = MNIST(args.data_path, train=False, download=True, transform=transform)\n",
    "        testloader = DataLoader(dst_test, batch_size=args.batch_real, shuffle=False)\n",
    "\n",
    "\n",
    "        ''' ResNet18 for MNIST dataset '''\n",
    "        # Set parameters for ResNet18\n",
    "        model_name = 'ResNet18'  \n",
    "        channel = 1  # Grayscale images (MNIST)\n",
    "        num_classes = 10  # MNIST has 10 classes\n",
    "        im_size = (32, 32)  # Actual MNIST image size is 28x28\n",
    "        \n",
    "        # Resize MNIST images from 28x28 to 32x32\n",
    "        transform_resize = transforms.Compose([\n",
    "            transforms.Resize(im_size),  # Resize to 32x32\n",
    "            transforms.ToTensor()  # Convert to tensor\n",
    "        ])\n",
    "    \n",
    "        # Get the network instance\n",
    "        resnet18 = get_network(model=model_name, channel=channel, num_classes=num_classes, im_size=im_size)\n",
    "        \n",
    "        # Modify the first layer if necessary (for MNIST grayscale images)\n",
    "        if hasattr(resnet18, 'model'):\n",
    "            resnet18.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    \n",
    "    optimizer3 = optim.SGD(resnet18.parameters(), lr=0.01) # Define optimizer\n",
    "    criterion = nn.CrossEntropyLoss() # Define loss function\n",
    "    mnist_loader = DataLoader(dst_train, batch_size=256, shuffle=True) # Create DataLoaders\n",
    "    scheduler3 = CosineAnnealingLR(optimizer3, T_max=20)# Cosine Annealing Scheduler\n",
    "\n",
    "    # Create a pool of models for evaluation\n",
    "    model_eval_pool = get_eval_pool(args.eval_mode, 'ResNet18', 'ResNet18')\n",
    "    accs_all_exps = dict()  # Record performance of all experiments\n",
    "    for key in model_eval_pool:\n",
    "        accs_all_exps[key] = []\n",
    "\n",
    "    data_save = []\n",
    "\n",
    "    for exp in range(args.num_exp):\n",
    "        print(f'\\n================== Exp {exp} ==================\\n')\n",
    "        print('Hyper-parameters: \\n', args.__dict__)\n",
    "        print('Evaluation model pool: ', model_eval_pool)\n",
    "\n",
    "        ''' Organize the real dataset '''\n",
    "        images_all = [torch.unsqueeze(dst_train[i][0], dim=0) for i in range(len(dst_train))]\n",
    "        labels_all = [dst_train[i][1] for i in range(len(dst_train))]\n",
    "        images_all = torch.cat(images_all, dim=0).to(args.device)\n",
    "        labels_all = torch.tensor(labels_all, dtype=torch.long, device=args.device)\n",
    "        \n",
    "        # Class-wise image indices\n",
    "        indices_class = [[] for _ in range(num_classes)]\n",
    "        for i, lab in enumerate(labels_all):\n",
    "            indices_class[lab].append(i)\n",
    "        \n",
    "        # Display class distribution\n",
    "        for c in range(num_classes):\n",
    "            print(f'class {c} = {len(indices_class[c])} real images')\n",
    "        \n",
    "        # Helper function to fetch random images from a class\n",
    "        def get_images(c, n):  # Get random n images from class c\n",
    "            idx_shuffle = np.random.permutation(indices_class[c])[:n]\n",
    "            return images_all[idx_shuffle]\n",
    "\n",
    "        ''' Initialize the synthetic data '''\n",
    "        image_syn = torch.randn(size=(num_classes * args.ipc, channel, im_size[0], im_size[1]), dtype=torch.float, requires_grad=True, device=args.device)\n",
    "        label_syn = torch.tensor([np.ones(args.ipc) * i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1)\n",
    "\n",
    "        # Initialize synthetic images with real or random noise\n",
    "        if args.init == 'real':\n",
    "            print('Initialize synthetic data from random real images')\n",
    "            for c in range(num_classes):\n",
    "                image_syn.data[c * args.ipc:(c + 1) * args.ipc] = get_images(c, args.ipc).detach().data\n",
    "        else:\n",
    "            print('Initialize synthetic data from random noise')\n",
    "\n",
    "        ''' Training '''\n",
    "        optimizer_img = torch.optim.SGD(resnet18.parameters(), lr=0.01)# optimizer_img = torch.optim.SGD([image_syn], lr=args.lr_img, momentum=0.5)\n",
    "        optimizer_img.zero_grad()\n",
    "        print('%s training begins' % time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "\n",
    "        for it in range(args.Iteration + 1):\n",
    "                ''' Evaluate synthetic data '''\n",
    "                if it in eval_it_pool:\n",
    "                    for model_eval in model_eval_pool:\n",
    "                        print(f'-------------------------\\nEvaluation\\nmodel_train = {'ResNet18'}, model_eval = {model_eval}, iteration = {it}')\n",
    "                        accs = []\n",
    "                        for it_eval in range(args.num_eval):\n",
    "                            net_eval = get_network(model_eval, channel, num_classes, im_size).to(args.device)\n",
    "                            image_syn_eval, label_syn_eval = copy.deepcopy(image_syn.detach()), copy.deepcopy(label_syn.detach())\n",
    "                            _, acc_train, acc_test = evaluate_synset(it_eval, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "                            accs.append(acc_test)\n",
    "                        print(f'Evaluate {len(accs)} random {model_eval}, mean = {np.mean(accs):.4f} std = {np.std(accs):.4f}\\n-------------------------')\n",
    "\n",
    "                        if it == args.Iteration:\n",
    "                            accs_all_exps[model_eval] += accs\n",
    "\n",
    "                    save_name = os.path.join(args.save_path, f'vis_{args.method}_{args.dataset}_{'ResNet18'}_{args.ipc}ipc_exp{exp}_iter{it}.png') \n",
    "                    image_syn_vis = copy.deepcopy(image_syn.detach().cpu())\n",
    "                    for ch in range(channel):\n",
    "                        image_syn_vis[:, ch] = image_syn_vis[:, ch] * std[ch] + mean[ch]\n",
    "                    # image_syn_vis[image_syn_vis < 0] = 0.0\n",
    "                    # image_syn_vis[image_syn_vis > 1] = 1.0\n",
    "                    image_syn_vis = copy.deepcopy(image_syn.detach().cpu())\n",
    "                    image_syn_vis = (image_syn_vis - image_syn_vis.min()) / (image_syn_vis.max() - image_syn_vis.min())\n",
    "                    save_image(image_syn_vis, save_name, nrow=args.ipc)\n",
    "\n",
    "                ''' Train synthetic data '''\n",
    "                net = get_network('ResNet18', channel, num_classes, im_size).to(args.device)\n",
    "                net.train()\n",
    "                for param in net.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "                embed = net.module.embed if torch.cuda.device_count() > 1 else net.embed\n",
    "\n",
    "                loss_avg = 0\n",
    "                loss = torch.tensor(0.0).to(args.device)\n",
    "                for c in range(num_classes):\n",
    "                    img_real = get_images(c, args.batch_real)\n",
    "                    img_syn = image_syn[c * args.ipc:(c + 1) * args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "\n",
    "                    if args.dsa:\n",
    "                        seed = int(time.time() * 1000) % 100000\n",
    "                        img_real = DiffAugment(img_real, args.dsa_strategy, seed=seed, param=args.dsa_param)\n",
    "                        img_syn = DiffAugment(img_syn, args.dsa_strategy, seed=seed, param=args.dsa_param)\n",
    "\n",
    "                    output_real = embed(img_real).detach()\n",
    "                    output_syn = embed(img_syn)\n",
    "\n",
    "                    # Calculate the distribution matching loss\n",
    "                    loss += torch.sum((torch.mean(output_real, dim=0) - torch.mean(output_syn, dim=0)) ** 2)\n",
    "\n",
    "                optimizer_img.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer_img.step()\n",
    "                loss_avg += loss.item()\n",
    "\n",
    "                if it % 10 == 0:\n",
    "                    print(f'{time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())} iter = {it:05d}, loss = {loss_avg:.4f}')\n",
    "\n",
    "                if it == args.Iteration:\n",
    "                    data_save.append([copy.deepcopy(image_syn.detach().cpu()), copy.deepcopy(label_syn.detach().cpu())])\n",
    "\n",
    "        print('%s training ends' % time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "\n",
    "    accs = []\n",
    "    for key in model_eval_pool:\n",
    "        accs.append(np.mean(accs_all_exps[key]))\n",
    "    print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'\n",
    "          % (args.num_exp, 'ResNet18', np.mean(accs), np.std(accs))) # % (args.num_exp, args.model, np.mean(accs), np.std(accs)))\n",
    "    \n",
    "    current_dir = os.getcwd()# Get the current working directory\n",
    "    # Save the results in the same directory as the script\n",
    "    torch.save({'data': data_save, 'accs_all_exps': accs_all_exps}, \n",
    "                os.path.join(current_dir, f'res_{args.method}_{args.dataset}_resnet18_{args.ipc}ipc.pt'))\n",
    "    \n",
    "    print(f'Data saved to {os.path.join(current_dir, f\"res_{args.method}_{args.dataset}_resnet18_{args.ipc}ipc.pt\")}')\n",
    "\n",
    "    return \n",
    "\n",
    "if __name__ == '__main__':\n",
    "     main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9c5609-ed22-4284-bb2d-1208ae10ac48",
   "metadata": {},
   "source": [
    "      ####################################### End of the code for Project A Task 2(a) ########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e044976-6b35-4fd0-9f9c-2cb012856f08",
   "metadata": {},
   "source": [
    "# This code provides:\n",
    "1. Learning the Condensed Images Using Distribution/Feature Matching:\n",
    "\n",
    "Feature Matching Surrogate Objective: The code includes a section where real and synthetic images' feature embeddings are compared for each class. The embeddings from real and synthetic data are obtained via the embed method of the network model (denoted by output_real for real data and output_syn for synthetic data).\n",
    "\n",
    "Distribution Matching Loss: The loss function, defined as the squared difference between the mean embeddings of real and synthetic images, represents a form of distribution matching. It aims to make the synthetic data resemble real data by minimizing the feature distribution distance between real and synthetic images: ---> \n",
    "*loss += torch.sum((torch.mean(output_real, dim=0) - torch.mean(output_syn, dim=0)) ** 2)*\n",
    "\n",
    "Optimization: The SGD optimizer (optimizer_img) updates the synthetic images to reduce the distribution matching loss, refining these images iteratively to better match real data features.\n",
    "\n",
    "2. Training the Network from Scratch on Condensed Images and Evaluating on Real Test Data:\n",
    "\n",
    "Training from Scratch: In each evaluation iteration (for-loop with it in eval_it_pool), a new network (net_eval) is initialized and trained from scratch using the condensed images (image_syn). This network is specifically trained only on synthetic images:\n",
    "\n",
    "*net_eval = get_network(model_eval, channel, num_classes, im_size).to(args.device)*\r\n",
    "*image_syn_eval, label_syn_eval = copy.deepcopy(image_syn.detach()), copy.deepcopy(label_syn.detach())*)\n",
    "*_, acc_train, acc_test = evaluate_synset(it_eval, net_eval, image_syn_eval, label_syn_eval, testloader, args))\n",
    "\n",
    "Ealuation on Real Test Data: After training, the network is evaluated on real test data (testloader). The evaluate_synset function calculates and logs the test accuracy, which measures how well the network generalizes from condensed (synthetic) training data to real test data.\r\n",
    "*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
