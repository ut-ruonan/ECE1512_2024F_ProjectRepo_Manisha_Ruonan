{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99d464ea-7d07-43f2-9921-a9880795bd45",
   "metadata": {},
   "source": [
    "# This is the code for the 'Task 1: Dataset Distillation with Attention Matching' Question 2. Dataset Distillation Learning - MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885e1edc-83e1-4081-931d-d4f68b756a91",
   "metadata": {},
   "source": [
    "    ########################################### Code start here for MNIST Dataset ############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31b2244-9cce-469f-8b05-bca8b41e4b45",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e613df-bcbb-470b-8cfb-24c7ffeb621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbimporter\n",
    "!pip install torch torchvision\n",
    "!pip install fvcore\n",
    "!pip install thop\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d24f5f7-77eb-41b6-a890-c32f02a6416d",
   "metadata": {},
   "source": [
    "# Import Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65900bd1-90ed-45fc-9542-9ca841f4fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\manis\\\\Documents\\\\ECE digital image processing_Class\\\\Project A')\n",
    "\n",
    "import nbimporter\n",
    "from networks import ConvNet\n",
    "from utils import get_dataset, get_loops, get_network, get_eval_pool, evaluate_synset\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import thop\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0fb42c-d17b-4057-812a-5ccad45d3736",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb3cfc-acbf-40a7-964f-436982a72d27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/mahagam3/Documents/ECE course/Project A'\n",
    "channel, im_size, num_classes, class_names, mean, std, mnist_train, mnist_test, testloader = get_dataset('MNIST', data_path)\n",
    "\n",
    "# print out some information about the datasets - MNIST\n",
    "print(f\"Channel: {channel}\")\n",
    "print(f\"Image size: {im_size}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Training dataset size: {len(mnist_train)}\")\n",
    "print(f\"Test dataset size: {len(mnist_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2019780c-46ae-4dbb-b604-0e50e389e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### MNIST Dataset ######\n",
    "# Initialize a counter for the classes\n",
    "class_counts = Counter()\n",
    "\n",
    "# Iterate through the training dataset\n",
    "for _, label in mnist_train:\n",
    "    class_counts[label] += 1  # Increment the count for the corresponding class\n",
    "\n",
    "# Print the number of images per class\n",
    "for class_label, count in class_counts.items():\n",
    "    print(f\"Class {class_label}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3135af04-8112-420e-9607-2fb7fe2a7062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for ConvNetD3\n",
    "channel_mnist = 1  # Grayscale images (MNIST)\n",
    "num_classes_mnist = 10  # MNIST has 10 classes\n",
    "im_size_mnist = (32, 32)  # Actual MNIST image size is 28x28\n",
    "\n",
    "# Resize MNIST images from 28x28 to 32x32\n",
    "transform_resize = transforms.Compose([\n",
    "    transforms.Resize(im_size_mnist),  # Resize to 32x32\n",
    "    transforms.ToTensor()  # Convert to tensor\n",
    "])\n",
    "\n",
    "# Instantiate ConvNetD3\n",
    "convnet3 = get_network('ConvNetD3', channel_mnist, num_classes_mnist, im_size_mnist).to('cpu')\n",
    "\n",
    "optimizer3 = optim.SGD(convnet3.parameters(), lr=0.01) # Define optimizer\n",
    "criterion = nn.CrossEntropyLoss() # Define loss function\n",
    "mnist_loader = DataLoader(mnist_train, batch_size=64, shuffle=True) # Create DataLoaders\n",
    "scheduler3 = CosineAnnealingLR(optimizer3, T_max=20)# Cosine Annealing Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d31cc-4416-44f1-96e7-8bc5edcb01cb",
   "metadata": {},
   "source": [
    "# Part 1 Question 2(a):\n",
    "Train the selected model with the original dataset and report the classification accuracy along  with floating-point operations per second (FLOPs) for the test set. Use SGD as an optimizer\n",
    "with a cosine annealing scheduler with an initial learning rate of 0.01 for 20 epochs. (For more information on experimental setting, look at the implementation details of [51]) These scores give you the upper bound benchmark evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98acb235-8581-4c67-9b07-e798f921d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def train_model(model, dataloader, optimizer, criterion, scheduler, num_epochs=20):\n",
    "    model.train()  # Set the model to training mode\n",
    "    start_time = time.time()  # Start timing\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in dataloader:\n",
    "            optimizer.zero_grad()  # Zero the parameter gradients\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Optimize the model\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()  # Step the learning rate scheduler\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}')\n",
    "\n",
    "    total_training_time = time.time() - start_time  # Calculate total time\n",
    "    print(f\"Training Time on Real MNIST Dataset: {total_training_time:.2f} seconds\")\n",
    "    return total_training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725146b6-54f3-45bc-9fae-7fe76545a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training ConvNet3 on MNIST\n",
    "print(\"Training ConvNet3 on MNIST...\")\n",
    "train_model(convnet3, mnist_loader, optimizer3, criterion, scheduler3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ab49d-f60a-4df8-8274-34c0d39da5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ConvNet3\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Evaluate ConvNet3 on test set\n",
    "mnist_test_loader = DataLoader(mnist_test, batch_size=64, shuffle=False)\n",
    "accuracy_mnist = evaluate_model(convnet3, mnist_test_loader)\n",
    "print(f'ConvNet3 Test Accuracy on MNIST: {accuracy_mnist:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c643f82c-c478-4886-a312-ce9b9f300811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flop is used to measure the coputational cost of running the model and to evaluate the efficiency of the learning model.\n",
    "# Calculate FLOPs (Floating Point Operations per Second)\n",
    "def calculate_flops(model, input_tensor):\n",
    "    from thop import profile\n",
    "    flops, params = profile(model, inputs=(input_tensor,))\n",
    "    return flops\n",
    "\n",
    "# Input tensor for calculating FLOPs\n",
    "input_tensor_mnist = torch.randn(60000, channel_mnist, 32, 32)\n",
    "flops_mnist = calculate_flops(convnet3, input_tensor_mnist)\n",
    "print(f'FLOPs for ConvNet3: {flops_mnist:.2f} FLOPs')\n",
    "\n",
    "# # This part gives the FLOPS: but there is an \"Unsupported operator aten::avg_pool2d encountered 3 time(s)\" error, meaning there can be \n",
    "# # This error comes because the FLIPS is not supported by the library \"from fvcore.nn import FlopCountAnalysis\"\n",
    "# from fvcore.nn import FlopCountAnalysis\n",
    "# flops_mnist = FlopCountAnalysis(convnet3, torch.randn(len(mnist_train), channel_mnist, im_size_mnist[0], im_size_mnist[1]).to(device)) # = len(mnist_train)=60000\n",
    "# print(f\"FLOPs for model {evaluate_model}: {flops_mnist.total()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7751ce18-9397-49c3-bb0b-c6903d06c4be",
   "metadata": {},
   "source": [
    "# Part 1: Question 2(b): \n",
    "Learn the synthetic dataset S using the selected model and Attention Matching algorithm. For initialization of condensed images, randomly select from real training images. The experimental setup can be found in Table 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea335e2c-e225-4207-b112-074662fef448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for MNIST\n",
    "K_mnist = 100\n",
    "T_mnist = 10\n",
    "eta_S_mnist = 0.1\n",
    "zeta_S_mnist = 1\n",
    "eta_theta_mnist = 0.01\n",
    "zeta_theta_mnist = 50\n",
    "lambda_mnist = 0.01\n",
    "num_classes_mnist = 10\n",
    "images_per_class_mnist = 10\n",
    "batch_size_mnist = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ed951-86ff-436b-86c5-500f711c0460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a synthetic dataset S by randomly sampling from a real dataset\n",
    "def generate_synthetic_dataset(real_dataset, num_classes, images_per_class):\n",
    "    synthetic_images = []\n",
    "    synthetic_labels = []\n",
    "    \n",
    "    for class_id in range(num_classes):\n",
    "        indices = random.sample(\n",
    "            [i for i, (_, label) in enumerate(real_dataset) if label == class_id],\n",
    "            images_per_class\n",
    "        )\n",
    "        synthetic_images.extend([real_dataset[i][0] for i in indices])\n",
    "        synthetic_labels.extend([real_dataset[i][1] for i in indices])\n",
    "    \n",
    "    return synthetic_images, synthetic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb6899b-c8f3-4f23-8b54-ec53a00b216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of generating synthetic samples for MNIST\n",
    "synthetic_images_mnist, synthetic_labels_mnist = generate_synthetic_dataset(\n",
    "    mnist_train, num_classes_mnist, images_per_class_mnist\n",
    ")\n",
    "# Convert synthetic images to a tensor\n",
    "synthetic_images_tensor_mnist = torch.stack(synthetic_images_mnist).to(device)\n",
    "synthetic_labels_tensor_mnist = torch.tensor(synthetic_labels_mnist).to(device)\n",
    "\n",
    "# Create DataLoader for the synthetic MNIST dataset\n",
    "synthetic_dataset_mnist = torch.utils.data.TensorDataset(synthetic_images_tensor_mnist, synthetic_labels_tensor_mnist)\n",
    "synthetic_loader_mnist = DataLoader(synthetic_dataset_mnist, batch_size=batch_size_mnist, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ce0aa-fac9-4908-8fb4-e9017bd4e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Save the synthetic images ########\n",
    "# Option 1: Save synthetic images as PNG files\n",
    "# Create a directory to save the synthetic images\n",
    "output_dir = \"synthetic_images_mnist\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save each synthetic image as a PNG file\n",
    "for idx, synthetic_image in enumerate(synthetic_images_mnist):\n",
    "    image_path = os.path.join(output_dir, f\"synthetic_image_{idx}.png\")\n",
    "    save_image(synthetic_image, image_path)\n",
    "\n",
    "print(f\"Synthetic images saved in {output_dir}\")\n",
    "\n",
    "# Option 2: Save synthetic images and labels as a .pt file\n",
    "torch.save({\n",
    "    'images': synthetic_images_tensor_mnist,\n",
    "    'labels': synthetic_labels_tensor_mnist\n",
    "}, \"synthetic_mnist.pt\")\n",
    "\n",
    "print(\"Synthetic images and labels saved as 'synthetic_mnist.pt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a62d3-b399-45a1-93dc-00ce4cf6a7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention_module import get_attention\n",
    "# Training Function with Attention Matching\n",
    "def train_with_attention_matching(model, synthetic_dataloader, optimizer, criterion, \n",
    "                                  param=0, exp=4, num_epochs=10, lambda_param=0.01):\n",
    "    model.train()\n",
    "    start_time = time.time()  # Start timing\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in synthetic_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass to get features\n",
    "            features = model(images)\n",
    "            # Get attention maps\n",
    "            attention_maps = get_attention(features, param=param, exp=exp)\n",
    "            \n",
    "            # Compute loss with attention matching\n",
    "            loss = criterion(features, labels)\n",
    "            # Incorporate task balance parameter λ\n",
    "            loss += lambda_param * torch.mean(attention_maps)  \n",
    "            \n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Optimize the model\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(synthetic_dataloader):.4f}')\n",
    "        total_training_time = time.time() - start_time  # Calculate total time\n",
    "    print(f\"Training Time on Real MNIST Dataset: {total_training_time:.2f} seconds\")\n",
    "    return total_training_time\n",
    "\n",
    "\n",
    "import torch.nn.functional as F \n",
    "# Optimizer setup for the model (using SGD as per the table)\n",
    "optimizer_mnist = torch.optim.SGD(convnet3.parameters(), lr=eta_theta_mnist)\n",
    "\n",
    "# Train the model using the synthetic datasets, cross_entropy measure how well the model predicts the classes.\n",
    "print(\"Training on MNIST dataset...\")\n",
    "train_with_attention_matching(convnet3, synthetic_loader_mnist, optimizer_mnist, F.cross_entropy, \n",
    "                              param=0, exp=4, num_epochs=T_mnist, lambda_param=lambda_mnist)\n",
    "\n",
    "accuracy_attention_mnist = evaluate_model(convnet3, mnist_test_loader)\n",
    "print(f'ConvNet7 Test Accuracy on MHIST: {accuracy_attention_mnist:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e856952-a380-4432-846b-208624dbb824",
   "metadata": {},
   "source": [
    "# Part 1: Question 2(c):\n",
    "Provide the visualization of condensed images per class for both MNIST and MHIST datasets. \n",
    "Do you think these condensed images are recognizable? Support your explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d04b15-e730-4c3c-82af-5adef08f7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_condensed_images(synthetic_images, num_classes, images_per_class, title, save_folder=None):\n",
    "    fig, axes = plt.subplots(num_classes, images_per_class, figsize=(10, 10))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    for class_id in range(num_classes):\n",
    "        for img_id in range(images_per_class):\n",
    "            idx = class_id * images_per_class + img_id\n",
    "            axes[class_id, img_id].imshow(synthetic_images[idx].squeeze(), cmap='gray')\n",
    "            axes[class_id, img_id].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the image if save_folder is provided\n",
    "    if save_folder:\n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "        save_path = os.path.join(save_folder, f\"{title.replace(' ', '_')}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Image saved to {save_path}\")\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "save_folder = 'Save_images'\n",
    "\n",
    "# Visualize condensed images for MNIST\n",
    "visualize_condensed_images(synthetic_images_tensor_mnist, num_classes_mnist, images_per_class_mnist, \n",
    "                           title=\"Condensed Images for MNIST\", save_folder=save_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd85781-f7ee-47e4-b46b-b153660a3b73",
   "metadata": {},
   "source": [
    "# Part 1 Question 2(d):\n",
    "Repeat parts 2b and 2c while the condensed images are initialized with Gaussian noise. Discuss in full detail the qualitative and quantitative results you have achieved. Are the results and visualizations are comparable with parts 2b and 2c?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931b908-2a87-47d2-9d88-4d36ad1febb9",
   "metadata": {},
   "source": [
    "# Repeat parts 2(b) while the condensed images are initialized with Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8587ae89-7afd-4823-9fc8-c7e4c64f7295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate synthetic dataset S with Gaussian noise\n",
    "# Reduce the standard deviation to make the noise less pronounced, leads to less spread in the distribution,......\n",
    "# meaning values stay closer to the mean. This results in less noise.\n",
    "def generate_synthetic_dataset_with_noise(real_dataset, num_classes, images_per_class, noise_std=0.8):\n",
    "    synthetic_images = []\n",
    "    synthetic_labels = []\n",
    "    \n",
    "    for class_id in range(num_classes):\n",
    "        indices = random.sample(\n",
    "            [i for i, (_, label) in enumerate(real_dataset) if label == class_id],\n",
    "            images_per_class\n",
    "        )\n",
    "        for i in indices:\n",
    "            # Generate Gaussian noise\n",
    "            noise = torch.normal(mean=0, std=noise_std, size=real_dataset[i][0].size())\n",
    "            synthetic_image = real_dataset[i][0] + noise\n",
    "            \n",
    "            # Ensure the pixel values are within valid range\n",
    "            synthetic_image = torch.clamp(synthetic_image, 0, 1)\n",
    "            \n",
    "            synthetic_images.append(synthetic_image)\n",
    "            synthetic_labels.append(real_dataset[i][1])\n",
    "    \n",
    "    return synthetic_images, synthetic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5a495-e216-43df-97fd-cc7fcbe19880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating synthetic samples for MNIST\n",
    "synthetic_images_mnist_noise, synthetic_labels_mnist_noise = generate_synthetic_dataset_with_noise(\n",
    "    mnist_train, num_classes_mnist, images_per_class_mnist\n",
    ") \n",
    "# Convert synthetic images to a tensor\n",
    "synthetic_images_tensor_mnist_noise = torch.stack(synthetic_images_mnist_noise).to(device)\n",
    "synthetic_labels_tensor_mnist_noise = torch.tensor(synthetic_labels_mnist_noise).to(device)\n",
    "\n",
    "# Create DataLoader for the synthetic MNIST dataset with noise\n",
    "synthetic_dataset_mnist_noise = torch.utils.data.TensorDataset(synthetic_images_tensor_mnist_noise, synthetic_labels_tensor_mnist_noise)\n",
    "synthetic_loader_mnist_noise = DataLoader(synthetic_dataset_mnist_noise, batch_size=batch_size_mnist, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963679e3-dae7-4054-a549-e4a06b99d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Save the synthetic images with noise ########\n",
    "# Option 1: Save synthetic images as PNG files\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Create a directory to save the synthetic images\n",
    "output_dir = \"synthetic_images_mnist_noise\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save each synthetic image as a PNG file\n",
    "for idx, synthetic_image in enumerate(synthetic_images_mnist_noise):\n",
    "    image_path = os.path.join(output_dir, f\"synthetic_image_{idx}.png\")\n",
    "    save_image(synthetic_image, image_path)\n",
    "\n",
    "print(f\"Synthetic images saved in {output_dir}\")\n",
    "\n",
    "# Option 2: Save synthetic images and labels as a .pt file\n",
    "torch.save({\n",
    "    'images': synthetic_images_tensor_mnist_noise,\n",
    "    'labels': synthetic_labels_tensor_mnist_noise\n",
    "}, \"synthetic_mnist_noise.pt\")\n",
    "\n",
    "print(\"Synthetic images and labels saved as 'synthetic_mnist_noise.pt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4faedb8-7660-4ef8-84b8-8da454350db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function with Attention Matching\n",
    "def train_with_attention_matching(model, synthetic_dataloader, optimizer, criterion, \n",
    "                                  param=0, exp=4, num_epochs=10, lambda_param=0.01):\n",
    "    model.train()\n",
    "    start_time = time.time()  # Start timing\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in synthetic_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass to get features\n",
    "            features = model(images)\n",
    "            # Get attention maps\n",
    "            attention_maps = get_attention(features, param=param, exp=exp)\n",
    "            \n",
    "            # Compute loss with attention matching\n",
    "            loss = criterion(features, labels)\n",
    "            # Incorporate task balance parameter λ\n",
    "            loss += lambda_param * torch.mean(attention_maps) \n",
    "            \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(synthetic_dataloader):.4f}')\n",
    "        total_training_time = time.time() - start_time  # Calculate total time\n",
    "    print(f\"Training Time on Real MNIST Dataset: {total_training_time:.2f} seconds\")\n",
    "    return total_training_time\n",
    "\n",
    "# Optimizer setup for the model (using SGD as per the table)\n",
    "optimizer_mnist_noise = torch.optim.SGD(convnet3.parameters(), lr=eta_theta_mnist)\n",
    "\n",
    "# Train the model using the synthetic datasets with Gaussian noise\n",
    "print(\"Training on MNIST dataset with Gaussian noise...\")\n",
    "train_with_attention_matching(convnet3, synthetic_loader_mnist_noise, optimizer_mnist_noise, \n",
    "                              F.cross_entropy, param=0, exp=4, num_epochs=T_mnist, lambda_param=lambda_mnist)\n",
    "\n",
    "accuracy_attention_mnist_noise = evaluate_model(convnet3, mnist_test_loader)\n",
    "print(f'ConvNet7 Test Accuracy on MHIST: {accuracy_attention_mnist_noise:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38498946-dd72-44e9-9b8b-52fd9489a336",
   "metadata": {},
   "source": [
    "#### Repeat parts 2(c) while the condensed images are initialized with Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b258ea2-ce34-40f2-98a5-be5c1d472e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_condensed_images(synthetic_images_tensor, num_classes, images_per_class, save_dir=\"Save_images\", title=\"Condensed Images\"):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    for class_id in range(num_classes):\n",
    "        class_images = synthetic_images_tensor[class_id * images_per_class:(class_id + 1) * images_per_class]\n",
    "        for i, image in enumerate(class_images):\n",
    "            plt.subplot(num_classes, images_per_class, class_id * images_per_class + i + 1)\n",
    "            plt.imshow(image.cpu().detach().numpy().squeeze(), cmap='gray')\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    save_path = os.path.join(save_dir, f\"{title.replace(' ', '_')}.png\") # Define the path where the image will be saved\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    print(f\"Image saved at: {save_path}\")\n",
    "    \n",
    "# Visualize and save condensed images for MNIST with Gaussian noise\n",
    "visualize_condensed_images(synthetic_images_tensor_mnist_noise, num_classes_mnist, images_per_class_mnist, \n",
    "                           save_dir=\"Save_images\", title=\"Condensed Images for MNIST with Gaussian Noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb74ec8f-b1bd-4c22-8d09-23dfb08fc7c2",
   "metadata": {},
   "source": [
    "# Part 1 Question 2(e):\n",
    "Now that you have had a chance to understand, learn, and visualize the condensed dataset, we can train the selected network from scratch on the condensed images. Train the selected network on a learned synthetic dataset (with 100 training images), then evaluate it on the\n",
    "real testing data. Compare the test accuracy performance and the training time with part 2a. Explain your results. (For a fair comparison, you should use the exact same experimental setting as part 2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66487c9-f0ff-4bab-9e6e-04b4b0296315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model on the synthetic condensed dataset\n",
    "def train_model_on_synthetic(model, dataloader, optimizer, criterion, scheduler, num_epochs=20):\n",
    "    model.train() \n",
    "    start_time = time.time()  \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in dataloader:\n",
    "            optimizer.zero_grad() \n",
    "            outputs = model(images)  \n",
    "            loss = criterion(outputs, labels)  \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()  # Step the learning rate scheduler\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}')\n",
    "    \n",
    "    total_training_time = time.time() - start_time\n",
    "    print(f\"Training Time on Condensed Dataset: {total_training_time:.2f} seconds\")\n",
    "    return total_training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ecf467-0940-475e-b75f-e97eddc9150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training on the condensed synthetic dataset (Part 2e)\n",
    "print(\"\\nTraining ConvNet3 on Condensed Synthetic Dataset...\")\n",
    "training_time_condensed = train_model_on_synthetic(convnet3, synthetic_loader_mnist, optimizer3, criterion, scheduler3)\n",
    "print(f\"Total Training Time on Condensed Dataset: {training_time_condensed:.2f} seconds\")\n",
    "\n",
    "# Evaluate model on the real test data (MNIST test set). This is the same evaluation model 'ConvNet3' applied to MNIST data in 2(a)\n",
    "accuracy_synthetic_mnist = evaluate_model(convnet3, mnist_test_loader)\n",
    "print(f'ConvNet3 Test Accuracy on Real MNIST after training on condensed dataset: {accuracy_synthetic_mnist:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63860115-2257-4755-b44f-3b18cf1fa194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input tensor for calculating FLOPs\n",
    "input_tensor_mnist = torch.randn(100, channel_mnist, 32, 32)\n",
    "flops_mnist = calculate_flops(convnet3, input_tensor_mnist)\n",
    "print(f'FLOPs for ConvNet3: {flops_mnist:.2f} FLOPs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5fda8b-7d1e-4a22-8b23-46042c877ad1",
   "metadata": {},
   "source": [
    "# Part 1 Question 3: Cross-architecture Generalization\n",
    "The ResNet18 is used in this section from networks.py file to evaluate its cross-architecture performance in terms of classification accuracy\r\n",
    "on the test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7fdfb5-f07c-447f-ae82-d0a170c506ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MNIST dataset #####\n",
    "# Define parameters\n",
    "model_name = 'ResNet18'  \n",
    "channel = 1              \n",
    "num_classes = 10          \n",
    "im_size = (32, 32)        \n",
    "\n",
    "transform_resize = transforms.Compose([\n",
    "    transforms.Resize(im_size), \n",
    "    transforms.ToTensor()  \n",
    "])\n",
    "\n",
    "# Get the network instance\n",
    "resnet18 = get_network(model=model_name, channel=channel, num_classes=num_classes, im_size=im_size)\n",
    "\n",
    "# Modify the first layer if necessary (for MNIST grayscale images)\n",
    "if hasattr(resnet18, 'model'):\n",
    "    resnet18.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "# Prepare the condensed MNIST dataset\n",
    "# Synthetic_images and synthetic_labels are defined from part 2b\n",
    "synthetic_dataset_mnist = TensorDataset(torch.stack(synthetic_images_mnist), torch.tensor(synthetic_labels_mnist))\n",
    "synthetic_loader_mnist = DataLoader(synthetic_dataset_mnist, batch_size=batch_size_mnist, shuffle=True)\n",
    "\n",
    "# Define optimizer, criterion, and scheduler\n",
    "optimizer_mnist = torch.optim.Adam(resnet18.parameters(), lr=0.001)\n",
    "criterion_mnist = torch.nn.CrossEntropyLoss()\n",
    "scheduler_mnist = torch.optim.lr_scheduler.StepLR(optimizer_mnist, step_size=10, gamma=0.1)\n",
    "\n",
    "# Train ResNet18 on the condensed MNIST dataset\n",
    "print(\"\\nTraining ResNet18 on Condensed MNIST Dataset...\")\n",
    "training_time_mnist = train_model_on_synthetic(resnet18, synthetic_loader_mnist, optimizer_mnist, criterion_mnist, scheduler_mnist)\n",
    "\n",
    "# Evaluate on the real MNIST test set\n",
    "mnist_test_loader = DataLoader(mnist_test, batch_size=64, shuffle=False)\n",
    "mnist_accuracy = evaluate_model(resnet18, mnist_test_loader)\n",
    "print(f'ResNet18 Test Accuracy on Real MNIST: {mnist_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d006b37-0aec-46ba-834c-b9fd3487e627",
   "metadata": {},
   "source": [
    "# Part 1 Question 4: Apply your synthetic small datasets to one of the machine learning applications\n",
    "Apply synthetic small dataset to continual leaning. So this case we have to train a model and evaluate the trained model.\n",
    "code is constructed by refering from: https://www.kaggle.com/code/dlarionov/continual-learning-on-permuted-mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8f05c9-c845-4f5e-9e93-28715492fd2e",
   "metadata": {},
   "source": [
    " *As of the refered code they have applied the code to premuted MNIST (original MNIST) dataset, \n",
    "So as of the task II, i did not consider the premutation, instead I applied the train and test dataset to the model. \n",
    "For this I used the Convnet3 model as I have used this to train the systhetic dataset earlier.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b8cc50-c29c-48ae-9fe6-227ca0e76a09",
   "metadata": {},
   "source": [
    "# Part II as of the experiment set up for continual learning in paper: \n",
    "DATASET CONDENSATION WITH GRADIENT MATCHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d40ff6-d6f3-4acb-b33c-b59494ec7f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b6ad76-8f59-4bdd-a514-34d9c1d768c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Device and hyperparameters\n",
    "# device = torch.device(\"cpu\") \n",
    "train_bs = 64  # Training batch size\n",
    "test_bs = 2000  # Testing batch size\n",
    "lr = 0.01  # Learning rate\n",
    "gamma = 0.9  # Decay factor\n",
    "num_tasks = 3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5959ded-cedc-4b6d-a6e7-94c25267b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create growing test sets at different stages: 2,000, 4,000, and 6,000 images\n",
    "def get_test_subset(mnist_test, num_samples):\n",
    "    \"\"\" Function to return a subset of MNIST test set with num_samples \"\"\"\n",
    "    indices = list(range(num_samples))\n",
    "    subset = torch.utils.data.Subset(mnist_test, indices)\n",
    "    return DataLoader(subset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b9443f-9fa0-45da-9611-c1bdfc6ee663",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 100  \n",
    "image_size = 28 * 28  \n",
    "\n",
    "transform_resize = transforms.Compose([\n",
    "    transforms.Resize(image_size),  \n",
    "    transforms.ToTensor() \n",
    "])\n",
    "synthetic_images_tensor_mnist = torch.randn(num_images * image_size) \n",
    "\n",
    "# Define the new shape\n",
    "channels = 1     \n",
    "height = 28      \n",
    "width = 28       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97680614-7b41-4fd8-a14d-74cb99b91fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Replay Buffer\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, buffer_size=100):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "\n",
    "    def add_to_buffer(self, samples):\n",
    "        for sample in samples:\n",
    "            # Ensure each sample has the correct number of elements\n",
    "            if len(sample) == 2:\n",
    "                input_tensor, target_tensor = sample\n",
    "                # Reshape the target tensor to ensure it is a single element\n",
    "                target_tensor = target_tensor.view(-1)  # Flatten to ensure it is a 1D tensor\n",
    "                self.buffer.append((input_tensor, target_tensor))\n",
    "                \n",
    "                # Maintain buffer size\n",
    "                if self.buffer_size and len(self.buffer) > self.buffer_size:\n",
    "                    self.buffer.pop(0)  # Remove oldest sample if buffer exceeds size\n",
    "            else:\n",
    "                print(f\"Unexpected sample shape: {sample}\")\n",
    "\n",
    "    def sample_from_buffer(self, batch_size):\n",
    "        samples = random.sample(self.buffer, min(len(self.buffer), batch_size))\n",
    "\n",
    "        inputs = [sample[0] for sample in samples]\n",
    "        targets = [sample[1] for sample in samples]\n",
    "\n",
    "        inputs_tensor = torch.stack(inputs) if inputs else torch.empty(0)\n",
    "        targets_tensor = torch.stack(targets) if targets else torch.empty(0)\n",
    "\n",
    "        return list(zip(inputs_tensor, targets_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ac6d0f-ca28-470d-8518-fb19a84e630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with replay buffer\n",
    "def train_model_with_replay(model, device, synthetic_loader, replay_buffer, optimizer, criterion, scheduler, replay_ratio=0.3):\n",
    "    model.train()\n",
    "    synthetic_data_iter = iter(synthetic_loader)\n",
    "    total_steps = len(synthetic_loader)\n",
    "    \n",
    "    for step in range(total_steps):\n",
    "        # Get current batch from synthetic data\n",
    "        try:\n",
    "            synthetic_batch = next(synthetic_data_iter)\n",
    "        except StopIteration:\n",
    "            synthetic_data_iter = iter(synthetic_loader)\n",
    "            synthetic_batch = next(synthetic_data_iter)\n",
    "        \n",
    "        # Sample from replay buffer\n",
    "        replay_batch = replay_buffer.sample_from_buffer(int(replay_ratio * len(synthetic_batch[0])))\n",
    "\n",
    "        # Debugging shapes\n",
    "        print(f\"Synthetic batch shape: {synthetic_batch[0].shape}\")\n",
    "        print(f\"Replay batch size: {len(replay_batch)}\")\n",
    "\n",
    "        # Add synthetic data to replay buffer\n",
    "        synthetic_samples = list(zip(\n",
    "            synthetic_images_tensor_mnist.view(-1, 1, 28, 28),\n",
    "            synthetic_labels_tensor_mnist\n",
    "        ))\n",
    "        replay_buffer.add_to_buffer(synthetic_samples)  # Add synthetic data to the replay buffer\n",
    "\n",
    "        # Combine synthetic data with replay data\n",
    "        if replay_batch:\n",
    "            print(\"Replay batch shapes:\")\n",
    "            for i, (input_tensor, target_tensor) in enumerate(replay_batch):\n",
    "                print(f\"Replay input shape[{i}]: {input_tensor.shape}, Replay target shape[{i}]: {target_tensor.shape}\")\n",
    "\n",
    "            # Ensure replay input tensors have the correct shape\n",
    "            replay_inputs = [x[0].unsqueeze(1) if len(x[0].shape) == 3 else x[0] for x in replay_batch] \n",
    "\n",
    "            combined_inputs = torch.cat([synthetic_batch[0]] + replay_inputs)\n",
    "            combined_targets = torch.cat([synthetic_batch[1]] + [x[1] for x in replay_batch])\n",
    "        else:\n",
    "            combined_inputs, combined_targets = synthetic_batch\n",
    "        \n",
    "        combined_inputs, combined_targets = combined_inputs.to(device), combined_targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(combined_inputs)\n",
    "        loss = criterion(output, combined_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b53158-ea8e-40bd-b975-050b1d770e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function with growing test set\n",
    "def test1_with_growing_test_set(model, device, mnist_test):\n",
    "    # Define the sizes for the growing test sets\n",
    "    test_set_sizes = [2000, 4000, 6000]\n",
    "    metrics = []\n",
    "    replay_buffer = ReplayBuffer(buffer_size=8000)  # Replay buffer with a limit of 8000 samples\n",
    "    \n",
    "    # Evaluate untrained model on MNIST test subsets\n",
    "    for size in test_set_sizes:\n",
    "        test_loader = get_test_subset(mnist_test, size)\n",
    "        test_acc = evaluate_model(model, test_loader)\n",
    "        print(f\"Test accuracy on {size} images: {test_acc:.2f}%\")\n",
    "        metrics.append(test_acc)\n",
    "    \n",
    "    for i in range(num_tasks):\n",
    "        print(f'Train on Task {i + 1}')\n",
    "        synthetic_loader, synthetic_data = tasks[i]  # Unpack the task\n",
    "        optimizer = torch.optim.Adadelta(model.parameters(), lr=lr)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "        \n",
    "        # Train the model on the current task using memory replay\n",
    "        train_model_with_replay(model, device, synthetic_loader, replay_buffer, optimizer, criterion_mnist, scheduler)\n",
    "        \n",
    "        # Add the synthetic data to the replay buffer\n",
    "        replay_buffer.add_to_buffer(synthetic_data.tensors)\n",
    "        \n",
    "        # Evaluate the model on different MNIST test set sizes\n",
    "        for size in test_set_sizes:\n",
    "            test_loader = get_test_subset(mnist_test, size)\n",
    "            test_acc = evaluate_model(model, test_loader)\n",
    "            print(f\"Test accuracy after training on Task {i+1} with {size} test images: {test_acc:.2f}%\")\n",
    "            metrics.append(test_acc)\n",
    "    \n",
    "    return metrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f64b0-9bae-4eaf-80f4-bbf4b443327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic dataset\n",
    "synthetic_labels_tensor_mnist = torch.randint(0, 10, (num_images,)) \n",
    "synthetic_images_tensor_mnist = synthetic_images_tensor_4d.view(-1, 1, 28, 28)\n",
    "\n",
    "# Create the synthetic dataset with the reshaped images\n",
    "synthetic_dataset_mnist = TensorDataset(synthetic_images_tensor_mnist, synthetic_labels_tensor_mnist)\n",
    "\n",
    "# Create tasks for different dataset sizes\n",
    "tasks = [\n",
    "    (DataLoader(TensorDataset(\n",
    "        synthetic_images_tensor_mnist[:2000 * (i + 1)], \n",
    "        synthetic_labels_tensor_mnist[:2000 * (i + 1)]\n",
    "    ), batch_size=256, shuffle=True), \n",
    "    TensorDataset(\n",
    "        synthetic_images_tensor_mnist[:2000 * (i + 1)], \n",
    "        synthetic_labels_tensor_mnist[:2000 * (i + 1)]\n",
    "    ))\n",
    "    for i in range(num_tasks)\n",
    "]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56af25d0-8afe-40de-b0ba-0506dfc9496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting multiple times (this case: 5 runs), compute the mean and standard deviation, and report them\n",
    "all_experiments = []\n",
    "num_experiments = 5\n",
    "\n",
    "for experiment in range(num_experiments):\n",
    "    print(f\"Running Experiment {experiment + 1}\")\n",
    "    model = convnet3.to(device)  # Reset the model for each experiment\n",
    "    degr_profile = test1_with_growing_test_set(model, device, mnist_test)\n",
    "    all_experiments.append(degr_profile)\n",
    "\n",
    "# Convert results to numpy array for easy computation of mean and std\n",
    "all_experiments = np.array(all_experiments)\n",
    "\n",
    "mean_results = np.mean(all_experiments, axis=0)\n",
    "std_results = np.std(all_experiments, axis=0)\n",
    "\n",
    "# Print mean and std for each task\n",
    "for i, (mean, std) in enumerate(zip(mean_results, std_results)):\n",
    "    print(f\"Task {i + 1} - Mean accuracy: {mean:.4f}, Standard deviation: {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22068b7-0c7e-4735-bec2-20edf8d4552a",
   "metadata": {},
   "source": [
    "          ############################# Code ends here for MNIST Dataset  ####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8223179-a2b1-4d07-922c-3ee27e44e9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca49c7ba-cc72-4f31-881b-605bcb6f4da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
